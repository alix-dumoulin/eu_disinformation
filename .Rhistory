corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 20)
}
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 20, scale=c(3.5,0.25))
}
get_wordcloud("Italy")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 20, width=12,height=8)
}
get_wordcloud("Italy")
wordcloud(corpus, scale=c(8,.2),min.freq=3,
max.words=Inf, random.order=FALSE, rot.per=.15)
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
corpus <- removeWords(corpus, stopwords("english"))
wordcloud(corpus, scale=c(8,.2),min.freq=3,
max.words=Inf, random.order=FALSE, rot.per=.15)
}
get_wordcloud("Italy")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, scale=c(8,.2),min.freq=3,
max.words=Inf, random.order=FALSE, rot.per=.15)
}
get_wordcloud("Italy")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud_tfidf <- function(raw, scale=c(8,.2),min.freq=3,
max.words=50, random.order=FALSE, rot.per=.15) {
dtm <- DocumentTermMatrix(raw, control = list(weighting = weightTfIdf))
freq <- data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=max.words)
}
wordcloud_tfidf(corpus)
}
get_wordcloud("Italy")
wordcloud_tfidf <- function(raw, scale=c(8,.2),min.freq=3,
max.words=20, random.order=FALSE, rot.per=.15) {
dtm <- DocumentTermMatrix(raw, control = list(weighting = weightTfIdf))
freq <- data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=max.words)
}
wordcloud_tfidf(corpus)
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud_tfidf <- function(raw, scale=c(8,.2),min.freq=3,
max.words=20, random.order=FALSE, rot.per=.15) {
dtm <- DocumentTermMatrix(raw, control = list(weighting = weightTfIdf))
freq <- data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=max.words)
}
wordcloud_tfidf(corpus)
}
get_wordcloud("Italy")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud_tfidf <- function(raw, scale=c(8,.2), min.freq=3,
max.words=20) {
dtm <- DocumentTermMatrix(raw, control = list(weighting = weightTfIdf))
freq <- data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=max.words)
}
wordcloud_tfidf(corpus)
}
get_wordcloud("Italy")
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud_tfidf <- function(raw, scale=c(8,.2), min.freq=3,
max.words=20) {
dtm <- DocumentTermMatrix(raw, control = list(weighting = weightTfIdf))
freq <- data.frame(sort(colSums(as.matrix(dtm)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=max.words)
}
wordcloud(corpus)
}
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
corpus <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 50)
}
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 50)
}
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 50, scale=c(8,.2),min.freq=3,rot.per=.15)
}
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
wordcloud(corpus, max.words = 20, scale=c(8,.2), min.freq=3,rot.per=.15)
}
get_wordcloud("France")
library(RColorBrewer)
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(corpus, max.words = 20, scale=c(8,.2), min.freq=3,rot.per=.15, colors = pal2)
}
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(corpus, max.words = 20, scale=c(8,.2), min.freq=3, rot.per=.55, colors = pal2)
}
get_wordcloud("France")
wordcloud(corpus, max.words = 20, scale=c(8,.2), min.freq=3, colors = pal2)
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## finally stem remaining words
corpus <- tm_map(corpus, stemDocument)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(corpus, max.words = 20, scale=c(8,.2), min.freq=3, colors = pal2)
}
get_wordcloud("France")
get_wordcloud <- function(country) {
country <- country
country_id <- all_countries$`@id`[all_countries$name==country]
reviews <- c()
for (i in 1:length(claims)) {
if((country_id %in% unlist(claims[[i]]$contentLocations))) {
reviews <- c(reviews, claims[[i]][["claimReview"]])
}
}
text <- all_claim_reviews$claimReviewed[all_claim_reviews$`@id` %in% reviews]
text <- removeWords(text, stopwords("english"))
corpus <- VCorpus(VectorSource(text))
## make lower case
corpus <- tm_map(corpus, content_transformer(tolower))
## remove white space
corpus <- tm_map(corpus, stripWhitespace)
## remove numbers
corpus <- tm_map(corpus, removeNumbers)
## remove punctuation
corpus <- tm_map(corpus, removePunctuation)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(corpus, max.words = 20, scale=c(8,.2), min.freq=3, colors = pal2)
}
get_wordcloud("France")
runApp('hackathon')
all_countries <- read_csv("all_countries.csv")
runApp('hackathon')
runApp('hackathon')
runApp('hackathon')
runApp('hackathon')
runApp('hackathon')
runApp('hackathon')
runApp('hackathon')
runApp('hackathon')
org_keywords <- merge(all_keywords, keywords_df,
by.x = "@id",
by.y = "unlist(keywords)")
all_keywords <- read_csv("all_keywords.csv")
claims <- jsonlite::read_json("claims.json")
all_claim_reviews <- read_csv("all_claim_reviews.csv")
all_organizations <- read_csv("all_organisations.csv")
all_news_articles <- read_csv("all_news_articles.csv")
all_countries <- read_csv("all_countries.csv")
all_languages <- read_csv("all_languages.csv")
org <- organisation
org_id <- all_organizations$`@id`[all_organizations$name==org]
articles_by_org <- subset(all_news_articles, all_news_articles$author==org_id)
claim_by_org <- articles_by_org$claim
keywords <- c()
for (i in 1:length(claims)) {
if(claims[[i]][["@id"]] %in% claim_by_org) {
keywords <- c(keywords, claims[[i]][["keywords"]])
}
}
for (i in 1:length(claims)) {
if(claims[[i]][["@id"]] %in% claim_by_org) {
keywords <- c(keywords, claims[[i]][["keywords"]])
}
}
claim_by_org <- articles_by_org$claim
articles_by_org <- subset(all_news_articles, all_news_articles$author==org_id)
org_id <- all_organizations$`@id`[all_organizations$name==org]
organisation = "Sputnik Arabic"
org <- organisation
org_id <- all_organizations$`@id`[all_organizations$name==org]
articles_by_org <- subset(all_news_articles, all_news_articles$author==org_id)
claim_by_org <- articles_by_org$claim
keywords <- c()
for (i in 1:length(claims)) {
if(claims[[i]][["@id"]] %in% claim_by_org) {
keywords <- c(keywords, claims[[i]][["keywords"]])
}
}
keywords_df <- as.data.frame(unlist(keywords))
org_keywords <- merge(all_keywords, keywords_df,
by.x = "@id",
by.y = "unlist(keywords)")
keywords_count_org <- org_keywords %>%
group_by(tolower(name)) %>%
count()
all_languages <- read_csv("all_languages.csv")
org <- organisation
org_id <- all_organizations$`@id`[all_organizations$name==org]
articles_by_org <- subset(all_news_articles, all_news_articles$author==org_id)
languages <- merge(articles_by_org, all_languages,
by.x = "inLanguage", by.y = "@id")
languages_count_org <- languages %>%
group_by(tolower(name.y)) %>%
count()
colnames(languages_count_org) <- c("Language", "Total")
runApp('~/Downloads/eu_disinformation-master/hackathon')
